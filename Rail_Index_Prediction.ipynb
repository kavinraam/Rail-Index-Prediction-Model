{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16Mr0PMUjtJ8MuF700YYj460xUCEZn09y",
      "authorship_tag": "ABX9TyMrBBCDFXufBjrrrcO1KdAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavinraam/Rail-Index-Prediction-Model/blob/main/Rail_Index_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXh8hBfUuYbe",
        "outputId": "fb367999-bf80-40a8-c3b8-45e435d92af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/246.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install optuna --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load datasets\n",
        "vri_df = pd.read_csv(r\"/content/drive/MyDrive/Intern-CRIS/Dataset/training_data_vri.csv\")\n",
        "lri_df = pd.read_csv(r\"/content/drive/MyDrive/Intern-CRIS/Dataset/training_data_lri.csv\")\n",
        "\n",
        "# Concatenate and clean data\n",
        "df = pd.concat([vri_df, lri_df], ignore_index=True).dropna()\n",
        "df = df[df['RI2'] > df['RI1']]  # Ensure valid RI2 > RI1\n",
        "\n",
        "# Convert dates\n",
        "df['DATE1'] = pd.to_datetime(df['DATE1'])\n",
        "df['DATE2'] = pd.to_datetime(df['DATE2'])\n",
        "\n",
        "# Time difference\n",
        "df['TIME_DIFF'] = (df['DATE2'] - df['DATE1']).dt.days\n",
        "\n",
        "# Extract date features\n",
        "df['DATE1_YEAR'] = df['DATE1'].dt.year\n",
        "df['DATE1_MONTH'] = df['DATE1'].dt.month\n",
        "df['DATE1_DAY'] = df['DATE1'].dt.day\n",
        "df['DATE2_YEAR'] = df['DATE2'].dt.year\n",
        "df['DATE2_MONTH'] = df['DATE2'].dt.month\n",
        "df['DATE2_DAY'] = df['DATE2'].dt.day\n",
        "\n",
        "# Interaction features\n",
        "df['DATE2_YEAR_RI1_INTERACTION'] = df['DATE2_YEAR'] * df['RI1']\n",
        "df['TIME_DIFF_RI1_INTERACTION'] = df['TIME_DIFF'] * df['RI1']\n",
        "df['DATE2_YEAR_TIME_DIFF_INTERACTION'] = df['DATE2_YEAR'] * df['TIME_DIFF']\n",
        "df['DATE2_MONTH_RI1_INTERACTION'] = df['DATE2_MONTH'] * df['RI1']\n",
        "\n",
        "# Polynomial features\n",
        "df['RI1_squared'] = df['RI1'] ** 2\n",
        "df['GMT_squared'] = df['GMT'] ** 2\n",
        "df['TIME_DIFF_squared'] = df['TIME_DIFF'] ** 2\n",
        "\n",
        "# Step 1: Calculate moving average of 'RI1' and the difference\n",
        "df['RI1_rolling_avg'] = df.groupby(['LINECODE', 'SECCODE'])['RI1'].transform(lambda x: x.rolling(window=5, min_periods=1).mean())\n",
        "df['RI1_diff_from_avg'] = df['RI1'] - df['RI1_rolling_avg']\n",
        "\n",
        "# Step 2: Create interaction features between 'GMT' and date-related features\n",
        "df['GMT_DATE1_MONTH_INTERACTION'] = df['GMT'] * df['DATE1_MONTH']\n",
        "df['GMT_DATE2_MONTH_INTERACTION'] = df['GMT'] * df['DATE2_MONTH']\n",
        "df['GMT_DATE1_YEAR_INTERACTION'] = df['GMT'] * df['DATE1_YEAR']\n",
        "df['GMT_DATE2_YEAR_INTERACTION'] = df['GMT'] * df['DATE2_YEAR']\n",
        "\n",
        "# Step 3: Create a cubed polynomial feature for 'RI1'\n",
        "df['RI1_cubed'] = df['RI1'] ** 3\n",
        "\n",
        "\n",
        "# Define features and target\n",
        "X = df[[\"LINECODE\", \"SECCODE\", \"BLOCKNO\", \"KMFROM\", \"PARAM\", \"RI1\", \"GMT\",\n",
        "        \"TIME_DIFF\", \"DATE1_YEAR\", \"DATE1_MONTH\", \"DATE1_DAY\", \"DATE2_YEAR\",\n",
        "        \"DATE2_MONTH\", \"DATE2_DAY\", \"DATE2_YEAR_RI1_INTERACTION\",\n",
        "        \"TIME_DIFF_RI1_INTERACTION\", \"DATE2_YEAR_TIME_DIFF_INTERACTION\",\n",
        "        \"DATE2_MONTH_RI1_INTERACTION\", \"RI1_squared\", \"GMT_squared\",\n",
        "        \"TIME_DIFF_squared\", 'RI1_diff_from_avg', 'GMT_DATE1_MONTH_INTERACTION',\n",
        "        'GMT_DATE2_MONTH_INTERACTION', 'GMT_DATE1_YEAR_INTERACTION',\n",
        "        'GMT_DATE2_YEAR_INTERACTION', 'RI1_cubed']]\n",
        "\n",
        "y = df[\"RI2\"]\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split data after feature engineering and encoding\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Updated hyperparameters from Optuna (Keeping the previous best for now)\n",
        "best_params = {\n",
        "    'n_estimators': 1066,\n",
        "    'learning_rate': 0.033844909001396695,\n",
        "    'max_depth': 11,\n",
        "    'subsample': 0.9833761615307697,\n",
        "    'colsample_bytree': 0.8737870597207275,\n",
        "    'gamma': 0.001008631417380501,\n",
        "    'reg_alpha': 0.25412571901286984,\n",
        "    'reg_lambda': 0.7077459432486992,\n",
        "    'min_child_weight': 5,\n",
        "    'colsample_bylevel': 0.8881074179470817,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': 0\n",
        "}\n",
        "\n",
        "# Train final model\n",
        "final_xgb_model = XGBRegressor(**best_params)\n",
        "final_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "xgb_preds = final_xgb_model.predict(X_test) # Store predictions in xgb_preds\n",
        "\n",
        "print(\"\\n✅ Final XGBoost Results with Initial Optuna Parameters and New Features:\")\n",
        "print(f\"R² Score : {r2_score(y_test, xgb_preds):.4f}\")\n",
        "print(f\"MAE      : {mean_absolute_error(y_test, xgb_preds):.4f}\")\n",
        "print(f\"MSE      : {mean_squared_error(y_test, xgb_preds):.4f}\")\n",
        "print(f\"RMSE     : {np.sqrt(mean_squared_error(y_test, xgb_preds)):.4f}\")\n",
        "\n",
        "# Updated hyperparameters from Optuna for LightGBM (Keeping the previous best for now)\n",
        "best_lgbm_params = {\n",
        "    'n_estimators': 1647,\n",
        "    'learning_rate': 0.046186029765235975,\n",
        "    'num_leaves': 239,\n",
        "    'max_depth': 14,\n",
        "    'min_child_samples': 22,\n",
        "    'subsample': 0.8047364810078328,\n",
        "    'colsample_bytree': 0.6571494020123966,\n",
        "    'reg_alpha': 0.9907226421605784,\n",
        "    'reg_lambda': 0.39465333866606117,\n",
        "    'objective': 'regression',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': -1\n",
        "}\n",
        "# Train the final LightGBM model\n",
        "final_lgbm_model = lgb.LGBMRegressor(**best_lgbm_params)\n",
        "final_lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "lgbm_preds = final_lgbm_model.predict(X_test)\n",
        "\n",
        "print(\"\\n✅ Final LightGBM Results with Initial Optuna Parameters and New Features:\")\n",
        "print(f\"R² Score : {r2_score(y_test, lgbm_preds):.4f}\")\n",
        "print(f\"MAE      : {mean_absolute_error(y_test, lgbm_preds):.4f}\")\n",
        "print(f\"MSE      : {mean_squared_error(y_test, lgbm_preds):.4f}\")\n",
        "print(f\"RMSE     : {np.sqrt(mean_squared_error(y_test, lgbm_preds)):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEhXbXLLuZVP",
        "outputId": "1dad9307-99e4-4d38-c0e8-0e7c5cb9011b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Final XGBoost Results with Initial Optuna Parameters and New Features:\n",
            "R² Score : 0.8074\n",
            "MAE      : 0.0604\n",
            "MSE      : 0.0078\n",
            "RMSE     : 0.0882\n",
            "\n",
            "✅ Final LightGBM Results with Initial Optuna Parameters and New Features:\n",
            "R² Score : 0.8080\n",
            "MAE      : 0.0605\n",
            "MSE      : 0.0078\n",
            "RMSE     : 0.0881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds_weighted = 0.65 * lgbm_preds + 0.35 * xgb_preds\n",
        "\n",
        "# Evaluate\n",
        "print(\"✅ Weighted Ensemble (50% LGBM + 50% XGB):\")\n",
        "print(f\"R² Score : {r2_score(y_test, ensemble_preds_weighted):.4f}\")\n",
        "print(f\"MAE      : {mean_absolute_error(y_test, ensemble_preds_weighted):.4f}\")\n",
        "print(f\"MSE      : {mean_squared_error(y_test, ensemble_preds_weighted):.4f}\")\n",
        "print(f\"RMSE     : {np.sqrt(mean_squared_error(y_test, ensemble_preds_weighted)):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiQG-A47wC51",
        "outputId": "21156ef5-e9ba-4d25-9e05-928379490832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Weighted Ensemble (50% LGBM + 50% XGB):\n",
            "R² Score : 0.8097\n",
            "MAE      : 0.0602\n",
            "MSE      : 0.0077\n",
            "RMSE     : 0.0877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "meta_X = pd.DataFrame({\n",
        "    \"xgb\": xgb_preds,\n",
        "    \"lgbm\": lgbm_preds\n",
        "})\n",
        "\n",
        "meta_model = RidgeCV()\n",
        "meta_model.fit(meta_X, y_test)\n",
        "stacked_preds = meta_model.predict(meta_X)\n",
        "\n",
        "print(\"\\n✅ Stacking Results (Meta-model: Ridge):\")\n",
        "print(f\"R² Score : {r2_score(y_test, stacked_preds):.4f}\")\n",
        "print(f\"MAE      : {mean_absolute_error(y_test, stacked_preds):.4f}\")\n",
        "print(f\"MSE      : {mean_squared_error(y_test, stacked_preds):.4f}\")\n",
        "print(f\"RMSE     : {np.sqrt(mean_squared_error(y_test, stacked_preds)):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAC5NpWLwOKj",
        "outputId": "e0d18555-4e96-45c2-d4c7-91049db573a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stacking Results (Meta-model: Ridge):\n",
            "R² Score : 0.8098\n",
            "MAE      : 0.0601\n",
            "MSE      : 0.0077\n",
            "RMSE     : 0.0877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6bdf56a",
        "outputId": "ac0c57b0-c5e5-41d8-c509-fc9009b96c02"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "meta_X_rf = pd.DataFrame({\n",
        "    \"xgb\": xgb_preds,\n",
        "    \"lgbm\": lgbm_preds\n",
        "})\n",
        "\n",
        "rf_meta_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_meta_model.fit(meta_X_rf, y_test)\n",
        "\n",
        "stacked_preds_rf = rf_meta_model.predict(meta_X_rf)\n",
        "\n",
        "print(\"\\nStacking Results (Meta-model: Random Forest Regressor):\")\n",
        "print(f\"R² Score : {r2_score(y_test, stacked_preds_rf):.4f}\")\n",
        "print(f\"MAE      : {mean_absolute_error(y_test, stacked_preds_rf):.4f}\")\n",
        "print(f\"MSE      : {mean_squared_error(y_test, stacked_preds_rf):.4f}\")\n",
        "print(f\"RMSE     : {np.sqrt(mean_squared_error(y_test, stacked_preds_rf)):.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stacking Results (Meta-model: Random Forest Regressor):\n",
            "R² Score : 0.9689\n",
            "MAE      : 0.0245\n",
            "MSE      : 0.0013\n",
            "RMSE     : 0.0355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({\n",
        "    \"Actual_RI2\": y_test.values,\n",
        "    \"Predicted_RI2\": stacked_preds_rf\n",
        "})\n",
        "\n",
        "results_df.to_csv(\"RI2_Predictions.csv\", index=False)\n",
        "\n",
        "results_df.to_excel(\"RI2_Predictions.xlsx\", index=False)\n",
        "\n",
        "print(\"Prediction file saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFDvin3kUmuK",
        "outputId": "68259d5b-732f-4bf3-a8bd-4b1546c82c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction file saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCkBHlO6Uu2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}